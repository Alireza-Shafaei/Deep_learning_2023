{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='data', train=True, transform=transform, download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "tesr_dataset = datasets.MNIST(root='data', train=False, transform=transform, download=True)\n",
        "test_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "def hot_one_encoding(label):\n",
        "    encoding = torch.zeros(10)\n",
        "    encoding[label] = 1.0\n",
        "    return encoding\n",
        "\n",
        "def prepare_data(images, labels):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "\n",
        "    for image, label in zip(images, labels):\n",
        "        hot_one_label = hot_one_encoding(label)\n",
        "\n",
        "        wrong_label = (label + 1) % 10\n",
        "        wrong_hot_one_label = hot_one_encoding(wrong_label)\n",
        "\n",
        "        inputs.append((image, hot_one_label))\n",
        "        inputs.append((image, wrong_hot_one_label))\n",
        "\n",
        "        targets.append(hot_one_label)\n",
        "        targets.append(wrong_hot_one_label)\n",
        "\n",
        "    return inputs, targets\n",
        "\n",
        "sample_inputs, sample_targets = prepare_data(*next(iter(train_loader)))\n",
        "\n",
        "print(\"Sample Input:\", sample_inputs[0])\n",
        "print(\"Sample Target:\", sample_targets[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIAppHLt1Vv6",
        "outputId": "21fe60cb-0228-44da-974e-188abcceb196"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input: (tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -0.4510,  1.0000,  0.9843,  0.8510, -0.1529, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.0275,\n",
            "           0.9373,  0.9843,  0.9765,  0.9765,  0.8118, -0.5843, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7961,\n",
            "           0.9765,  0.9843,  0.9765,  0.9765,  0.9765,  0.7961, -0.7098,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.7961,\n",
            "           0.9765,  0.7882,  0.6000,  0.8353,  0.9765,  0.9765, -0.3490,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.3647,\n",
            "           0.5059, -0.7255, -1.0000, -0.5137,  0.8196,  0.9765,  0.4118,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -0.3961,  0.9765,  0.5686,\n",
            "          -0.8902, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -0.7412,  0.7882,  0.9765,\n",
            "          -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,  0.4196,  0.9765,\n",
            "          -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -0.6549,  0.9294,  0.9765,\n",
            "          -0.6235, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -0.6157,  0.9765,  0.4353,\n",
            "          -0.9765, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -0.9608, -0.8980, -0.9451,\n",
            "          -1.0000, -1.0000, -1.0000, -0.3490,  0.6706,  0.9843, -0.0745,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -0.8588, -0.0824,  0.4196,  0.9765,  0.6157,\n",
            "          -0.3098, -0.8039, -0.7176,  0.6549,  0.9765,  0.7020, -0.7961,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -0.8196, -0.0745,  0.7647,  0.9765,  0.9765,  0.9765,  0.9765,\n",
            "           0.9765,  0.9843,  0.9765,  0.9765,  0.9765, -0.0824, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9608,\n",
            "           0.3725,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,\n",
            "           0.9765,  0.9843,  0.9765,  0.9765,  0.9765,  0.2784, -0.9059,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.5765,\n",
            "           0.9765,  0.8902,  0.5059,  0.2314, -0.4353,  0.0980,  0.9765,\n",
            "           0.9765,  0.9843,  0.9765,  0.9765,  0.9765,  0.9765,  0.5451,\n",
            "           0.0980, -0.7020, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9216,  0.7804,\n",
            "           0.9765,  0.6000, -1.0000, -1.0000, -0.2157,  0.6941,  0.9765,\n",
            "           0.9765,  0.9843,  0.9765,  0.9765,  0.9765,  0.9765,  0.9765,\n",
            "           0.9765,  0.7961, -0.1294, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8980,  0.9765,\n",
            "           0.8824, -0.3804, -0.8353,  0.3882,  0.9059,  0.9765,  0.9765,\n",
            "           0.6627, -0.1686, -0.6235, -0.6235,  0.0039,  0.3098,  0.8196,\n",
            "           0.9765,  0.9765,  0.1216, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8980,  0.9765,\n",
            "           0.9373,  0.7020,  0.7647,  0.9765,  0.9765,  0.9765,  0.6471,\n",
            "          -0.3569, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7882,\n",
            "          -0.7176, -0.7176, -0.8431, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8980,  0.9765,\n",
            "           0.9765,  0.9765,  0.9765,  0.9765,  0.6941, -0.2314, -0.8902,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9451,  0.5765,\n",
            "           0.9765,  0.7961,  0.7098,  0.2549, -0.7647, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
            "         [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
            "          -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]))\n",
            "Sample Target: tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PositiveLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(PositiveLayer, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "class NegativeLayer(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(NegativeLayer, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "\n",
        "class LearningNetwork(nn.Module):\n",
        "    def __init__(self, positive_layer, negative_layer):\n",
        "        super(LearningNetwork, self).__init__()\n",
        "        self.positive_layer = positive_layer\n",
        "        self.negative_layer = negative_layer\n",
        "\n",
        "    def forward(self, positive_data, negative_data):\n",
        "        positive_output = self.positive_layer(positive_data)\n",
        "        negative_output = self.negative_layer(negative_data)\n",
        "        return positive_output, negative_output\n",
        "\n",
        "def custom_loss(threshold, positive_data, negative_data):\n",
        "    return torch.mean(torch.log(1 + torch.exp(torch.cat([threshold - positive_data, negative_data - threshold]))))\n",
        "\n",
        "input_size = 28 * 28\n",
        "output_size = 10\n",
        "threshold = 0.5\n",
        "positive_layer = PositiveLayer(input_size, output_size)\n",
        "negative_layer = NegativeLayer(input_size, output_size)\n",
        "model = LearningNetwork(positive_layer, negative_layer)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "def train(model, optimizer, num_epochs):\n",
        "    for epoch in range(num_epochs):\n",
        "        for batch_images, batch_labels in train_loader:\n",
        "            inputs, targets = prepare_data(batch_images, batch_labels)\n",
        "\n",
        "            positive_data, _ = inputs[0]\n",
        "            negative_data, _ = inputs[1]\n",
        "\n",
        "            positive_output, negative_output = model(positive_data.flatten(), negative_data.flatten())\n",
        "            loss = custom_loss(threshold, positive_output, negative_output)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "num_epochs = 10\n",
        "train(model, optimizer, num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMosWB0d4I-D",
        "outputId": "f986c2cf-07b7-46a5-f26e-5084868ebdac"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 0.050567857921123505\n",
            "Epoch 2/10, Loss: 0.019389096647500992\n",
            "Epoch 3/10, Loss: 0.008798522874712944\n",
            "Epoch 4/10, Loss: 0.01200067438185215\n",
            "Epoch 5/10, Loss: 0.007391289807856083\n",
            "Epoch 6/10, Loss: 0.0076102628372609615\n",
            "Epoch 7/10, Loss: 0.007415018975734711\n",
            "Epoch 8/10, Loss: 0.004356746096163988\n",
            "Epoch 9/10, Loss: 0.008527066558599472\n",
            "Epoch 10/10, Loss: 0.0043122125789523125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The loss function tries to penalize deviations from the desired conditions. It encourages the model to assign high values to positive data (where\n",
        "threshold - positive data\n",
        "threshold - positive data is negative) and low values to negative data (where\n",
        "negative data - threshold\n",
        "negative data - threshold is negative). The logarithmic term ensures that the penalty is better for larger deviations."
      ],
      "metadata": {
        "id": "ed7j2u3HZl-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            inputs, targets = prepare_data(images, labels)\n",
        "\n",
        "            positive_data, _ = inputs[0]\n",
        "            negative_data, _ = inputs[1]\n",
        "\n",
        "            positive_output, negative_output = model(positive_data.flatten(), negative_data.flatten())\n",
        "\n",
        "            # Assuming positive_output is a 1D tensor\n",
        "            predicted_labels = torch.argmax(positive_output)\n",
        "\n",
        "            correct += (predicted_labels == labels[0]).item()\n",
        "    size = len(data_loader.dataset)\n",
        "    accuracy = correct / size\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "train_accuracy = evaluate(model, train_loader)\n",
        "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cZ7f2hrO7U6",
        "outputId": "a3dd2724-dcb1-457d-e80b-279619a57429"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the MNIST dataset.\n",
        "\n",
        "Generating data by converting labels into one-hot vectors and placing them in the images.\n",
        "\n",
        "Creating pairs of correct and incorrect labels for each image.\n",
        "\n",
        "Positive and Negative layers are created as linear layers.\n",
        "\n",
        "The Learning Network is composed of these layers.\n",
        "\n",
        "Custom loss is defined to have the goodness conditions, with a threshold for positive and negative data.\n",
        "\n",
        "The loss function encourages correct prediction for positive data and incorrect prediction for negative data.\n",
        "\n",
        "Stochastic Gradient Descent (SGD) is employed as the optimizer.\n",
        "\n",
        "Training involves iterating through epochs and batches, forward-passing positive and negative data through the model, calculating the loss, and updating the model parameters.\n",
        "\n",
        "After training, the model's performance saved by evaluating its accuracy on the training dataset."
      ],
      "metadata": {
        "id": "7Y_yznhVcDdh"
      }
    }
  ]
}